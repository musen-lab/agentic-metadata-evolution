{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "  if not os.environ.get(var):\n",
    "    os.environ[var] = getpass.getpass(f\"Enter {var}: \")\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"metadata-harmonization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../src\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install langchain\n",
    "%pip install langchain-openai\n",
    "%pip install langchain-core\n",
    "%pip install langgraph\n",
    "%pip install pydantic\n",
    "%pip install jsonpatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Dict, Any, List\n",
    "from langchain_core.tools import tool\n",
    "import jsonpatch\n",
    "import copy\n",
    "\n",
    "def apply_patch(document: Dict[str, Any], patches: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "  \"\"\"\n",
    "  Apply a JSON Patch to a JSON document.\n",
    "  \n",
    "  Args:\n",
    "    document: The original JSON document to patch\n",
    "    patch: A list of JSON Patch operations\n",
    "  \n",
    "  Returns:\n",
    "    The patched JSON document\n",
    "    \n",
    "  Raises:\n",
    "    jsonpatch.JsonPatchException: If the patch is invalid or cannot be applied\n",
    "  \"\"\"\n",
    "  print(f\"Applying patch: {patches}\")\n",
    "  try:\n",
    "    # Create a deep copy of the document to avoid modifying the original\n",
    "    document_copy = copy.deepcopy(document)\n",
    "    \n",
    "    # Create a JsonPatch object from the patch list\n",
    "    json_patch = jsonpatch.JsonPatch(patches)\n",
    "    print(f\"JsonPatch: {json_patch}\")\n",
    "    \n",
    "    # Apply the patch to the document\n",
    "    patched_document = json_patch.apply(document_copy)\n",
    "    \n",
    "    return patched_document\n",
    "    \n",
    "  except jsonpatch.JsonPatchException as e:\n",
    "    raise ValueError(f\"Failed to apply JSON patch: {str(e)}\")\n",
    "  except Exception as e:\n",
    "    raise ValueError(f\"Unexpected error while applying patch: {str(e)}\")\n",
    "\n",
    "@tool\n",
    "class Done(BaseModel):\n",
    "  \"\"\"Task is done.\"\"\"\n",
    "  done: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triage Input Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assistant.states import AppState\n",
    "from assistant.schemas import RNASEQ_SCHEMA\n",
    "from typing import Literal\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import END\n",
    "\n",
    "def triage_metadata(state: AppState) -> Command[Literal[\"agent_manager\", END]]:\n",
    "  \"\"\"\n",
    "  Triage metadata based on the dataset type in the input metadata.\n",
    "  \"\"\"\n",
    "  # TODO: Add a check to see if the dataset type is in the list of supported dataset types\n",
    "  dataset_type = state[\"document\"].get(\"dataset_type\")\n",
    "\n",
    "  schema = None\n",
    "  if dataset_type == \"RNAseq\":\n",
    "    goto = \"agent_manager\"\n",
    "    schema = RNASEQ_SCHEMA\n",
    "  else:\n",
    "    goto = END\n",
    "\n",
    "  return Command(goto=goto, update={\n",
    "    \"schema\": schema\n",
    "  })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assistant.states import AppState\n",
    "from typing import Literal\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import END\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Initialize the LLM\n",
    "# agent_manager_llm = init_chat_model(\"openai:gpt-4.1\", temperature=0.0)\n",
    "\n",
    "def agent_manager_llm_call(state: AppState) -> Command[Literal[\"data_analyst\", END]]:\n",
    "  \"\"\"\n",
    "  Agent to manage the metadata evolution process. This agent decides what to do with the metadata:\n",
    "  - If patches are available, apply them to the input metadata and end the workflow.\n",
    "  - If instructions and patches are not available, route to data_analyst to plan the instructions for updating the metadata.\n",
    "  \"\"\"\n",
    "  patches = state.get(\"patches\", [])\n",
    "\n",
    "  if len(patches) > 0:\n",
    "    # Apply patches to the input metadata\n",
    "    try:\n",
    "      new_metadata = apply_patch({}, patches)\n",
    "      return Command(\n",
    "          goto=END,\n",
    "          update={\n",
    "            \"messages\": [{\n",
    "              \"role\": \"assistant\", \n",
    "              \"content\": f\"Successfully generated new metadata: {new_metadata}\"\n",
    "            }]\n",
    "          }\n",
    "        )\n",
    "    except Exception as e:\n",
    "      return Command(\n",
    "        goto=END,\n",
    "        update={\n",
    "          \"messages\": [{\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Error applying patches: {str(e)}. Task failed.\"\n",
    "          }]\n",
    "        }\n",
    "      )\n",
    "  else:\n",
    "    return Command(\n",
    "      goto=\"data_analyst\",\n",
    "      update={\n",
    "        \"messages\": [{\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": f\"Assigning task to data_analyst to plan the metadata generation instructions.\"\n",
    "        }]\n",
    "      }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assistant.states import AppState\n",
    "from assistant.models import Instruction\n",
    "from assistant.prompts import data_analyst_system_prompt\n",
    "\n",
    "from typing import Literal\n",
    "from langgraph.types import Command\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Initialize the LLM with structured output\n",
    "data_analyst_llm = init_chat_model(\"openai:gpt-4.1-mini\", temperature=0.0).with_structured_output(Instruction)\n",
    "\n",
    "def data_analyst_llm_call(state: AppState) -> Command[Literal[\"programmer\"]]:\n",
    "  \"\"\"\n",
    "  Agent to analyze the input metadata and target schema to create a list of instructions to generate metadata that conforms to the target schema.\n",
    "  \"\"\"\n",
    "  print(\"Calling data analyst agent...\")\n",
    "  input_metadata = state[\"document\"].get('metadata')\n",
    "  target_schema = state[\"schema\"]\n",
    "  \n",
    "  instructions = []\n",
    "  for field in target_schema:\n",
    "    instruction = data_analyst_llm.invoke(\n",
    "      # Add the system prompt\n",
    "      [\n",
    "        { \"role\": \"system\", \"content\": data_analyst_system_prompt.format(metadata=input_metadata) },\n",
    "        { \"role\": \"user\", \"content\": f\"Create an instruction to generate a metadata field following the schema: {field}\" }\n",
    "      ]\n",
    "    )\n",
    "    print(f\"  Producing instruction: {instruction}\")\n",
    "    # Extract instructions directly from the structured response\n",
    "    instructions.append(instruction)\n",
    "  \n",
    "  return Command(\n",
    "    goto=\"programmer\", \n",
    "    update={\n",
    "      \"messages\": [{\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": f\"Created {len(instructions)} instructions for generating metadata.\"\n",
    "      }],\n",
    "      \"instructions\": instructions\n",
    "    }\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assistant.prompts import programmer_system_prompt, programmer_user_prompt\n",
    "from assistant.states import AppState\n",
    "from assistant.models import JsonPatch\n",
    "\n",
    "import json\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "programmer_llm = init_chat_model(\"openai:gpt-4o\", temperature=0.0).with_structured_output(JsonPatch)\n",
    "\n",
    "def programmer_llm_call(state: AppState) -> Command[Literal[\"agent_manager\"]]:\n",
    "  \"\"\"\n",
    "  Create a JSON Patch object to update the metadata.\n",
    "\n",
    "  Args:\n",
    "    instructions: A list of instructions to create a JSON Patch object.\n",
    "\n",
    "  Returns:\n",
    "    A list of JSON Patch objects.\n",
    "  \"\"\"\n",
    "  print(\"Calling programmer agent...\")\n",
    "  instructions = state[\"instructions\"]\n",
    "  \n",
    "  patches = []\n",
    "  for instruction in instructions:\n",
    "    user_prompt = programmer_user_prompt.format(instruction=instruction.command)\n",
    "    response = programmer_llm.invoke(\n",
    "        [\n",
    "          { \"role\": \"system\", \"content\": programmer_system_prompt },\n",
    "          { \"role\": \"user\", \"content\": user_prompt }\n",
    "        ]\n",
    "    )\n",
    "    patch = response.model_dump()\n",
    "\n",
    "    # Convert back to proper JSON patch format\n",
    "    if patch.get('value_json'):\n",
    "        patch['value'] = json.loads(patch['value_json'])\n",
    "        del patch['value_json']\n",
    "\n",
    "    print(f\"  Producing patch: {patch}\")\n",
    "    patches.append(patch)\n",
    "\n",
    "  return Command(\n",
    "    goto=\"agent_manager\", \n",
    "    update={\n",
    "      \"messages\": [{\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": f\"Created {len(patches)} patches for updating themetadata.\"\n",
    "      }],\n",
    "      \"patches\": patches\n",
    "    }\n",
    "  )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from assistant.states import AppState\n",
    "\n",
    "def create_metadata_updating_workflow():\n",
    "  \"\"\"\n",
    "  Create the complete LangGraph workflow for updating the metadata.\n",
    "  \n",
    "  Flow: \n",
    "  1. triage_metadata -> agent_manager \n",
    "  2. agent_manager -> (if no patches) data_analyst -> programmer -> agent_manager\n",
    "  3. agent_manager -> (if patches exist) apply patches -> END\n",
    "  \"\"\"\n",
    "  \n",
    "  # Create the StateGraph\n",
    "  workflow = StateGraph(AppState)\n",
    "  \n",
    "  # Add nodes to the graph\n",
    "  workflow.add_node(\"triage\", triage_metadata)\n",
    "  workflow.add_node(\"agent_manager\", agent_manager_llm_call)  \n",
    "  workflow.add_node(\"data_analyst\", data_analyst_llm_call)\n",
    "  workflow.add_node(\"programmer\", programmer_llm_call)\n",
    "  \n",
    "  # Set the entry point\n",
    "  workflow.set_entry_point(\"triage\")\n",
    "  \n",
    "  # Compile the graph\n",
    "  app = workflow.compile()\n",
    "  \n",
    "  return app\n",
    "\n",
    "# Create the workflow\n",
    "app = create_metadata_updating_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assistant.utils import show_graph\n",
    "\n",
    "show_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_document = {\n",
    "    \"uuid\": \"421007293469db7b528ce6478c00348d\",\n",
    "    \"hubmap_id\": \"HBM575.XFCT.276\",\n",
    "    \"status\": \"Published\",\n",
    "    \"group_name\": \"University of California San Diego TMC\",\n",
    "    \"dataset_type\": \"RNAseq\",\n",
    "    \"metadata\": {\n",
    "      \"acquisition_instrument_model\": \"NovaSeq\",\n",
    "      \"acquisition_instrument_vendor\": \"Illumina\",\n",
    "      \"analyte_class\": \"RNA\",\n",
    "      \"assay_category\": \"sequence\",\n",
    "      \"assay_type\": \"SNARE2-RNAseq\",\n",
    "      \"cell_barcode_offset\": \"10,48,86\",\n",
    "      \"cell_barcode_read\": \"R2\",\n",
    "      \"cell_barcode_size\": \"8,8,8\",\n",
    "      \"contributors_path\": \"extras/bukmap_20190822_contributors.tsv\",\n",
    "      \"data_path\": \".\",\n",
    "      \"donor_id\": \"UCSD0006\",\n",
    "      \"execution_datetime\": \"2019-08-22 11:00\",\n",
    "      \"is_targeted\": \"False\",\n",
    "      \"is_technical_replicate\": \"False\",\n",
    "      \"library_adapter_sequence\": \"CTGTCTCTTATACACATCT\",\n",
    "      \"library_average_fragment_size\": \"700\",\n",
    "      \"library_construction_protocols_io_doi\": \"10.17504/protocols.io.be5gjg3w\",\n",
    "      \"library_final_yield_unit\": \"ng\",\n",
    "      \"library_final_yield_value\": \"673\",\n",
    "      \"library_id\": \"KM47\",\n",
    "      \"library_layout\": \"paired-end\",\n",
    "      \"library_pcr_cycles\": \"19\",\n",
    "      \"library_pcr_cycles_for_sample_index\": \"12\",\n",
    "      \"operator\": \"Nongluk Plongthongkum\",\n",
    "      \"operator_email\": \"nplongth@eng.ucsd.edu\",\n",
    "      \"pi\": \"Kun Zhang\",\n",
    "      \"pi_email\": \"kzhang@eng.ucsd.edu\",\n",
    "      \"protocols_io_doi\": \"10.17504/protocols.io.be5gjg3w\",\n",
    "      \"rnaseq_assay_input\": \"16000\",\n",
    "      \"rnaseq_assay_method\": \"SNARE-Seq2-RNA\",\n",
    "      \"sc_isolation_cell_number\": \"4420000\",\n",
    "      \"sc_isolation_enrichment\": \"FACS\",\n",
    "      \"sc_isolation_entity\": \"nucleus\",\n",
    "      \"sc_isolation_protocols_io_doi\": \"10.17504/protocols.io.ufketkw\",\n",
    "      \"sc_isolation_quality_metric\": \"OK\",\n",
    "      \"sc_isolation_tissue_dissociation\": \"dounce\",\n",
    "      \"sequencing_phix_percent\": \"20\",\n",
    "      \"sequencing_read_format\": \"70/6/104\",\n",
    "      \"sequencing_read_percent_q30\": \"94.07\",\n",
    "      \"sequencing_reagent_kit\": \"NovaSeq 6000 S4 Reagent\",\n",
    "      \"tissue_id\": \"UCSD0006-RK-1-1-1\"\n",
    "    }\n",
    "  }\n",
    "\n",
    "app.invoke({\"document\": example_document})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
